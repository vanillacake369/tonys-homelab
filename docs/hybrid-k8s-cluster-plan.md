# Hybrid K8s Cluster êµ¬í˜„ ê³„íš

## ê°œìš”

AMD Hawk Point iGPU (Radeon 780M)ì˜ VM passthrough í•œê³„ë¡œ ì¸í•´, **í˜¸ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ GPUë¥¼ í™œìš©**í•˜ëŠ” Hybrid Cluster êµ¬ì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤.

```mermaid
flowchart TB
    subgraph Host["í˜¸ìŠ¤íŠ¸ (homelab) - Bare Metal"]
        GPU["AMD 780M iGPU<br/>ROCm/OpenCL"]
        K8S_HOST["K8s Worker Node<br/>(GPU ì›Œí¬ë¡œë“œ)"]
        OLLAMA["Ollama / LocalAI<br/>LLM ì¶”ë¡ "]
    end

    subgraph VMs["MicroVMs"]
        MASTER["k8s-master<br/>Control Plane"]
        WORKER1["k8s-worker-1<br/>(CPU only)"]
        WORKER2["k8s-worker-2<br/>(CPU only)"]
    end

    subgraph Cluster["K8s Cluster"]
        API["API Server"]
    end

    MASTER --> API
    K8S_HOST --> |"join"| API
    WORKER1 --> |"join"| API
    WORKER2 --> |"join"| API
    GPU --> K8S_HOST
    K8S_HOST --> OLLAMA

    style GPU fill:#76b900,color:#fff
    style K8S_HOST fill:#326ce5,color:#fff
    style MASTER fill:#326ce5,color:#fff
```

---

## Phase 1: GPU ë¹„í™œì„±í™” ë° ì •ë¦¬

### ëª©í‘œ
k8s-worker-1ì—ì„œ GPU passthrough ì„¤ì •ì„ ì œê±°í•˜ê³  ì•ˆì •ì ì¸ VM ìš´ì˜ í™˜ê²½ êµ¬ì¶•

### ì‘ì—… í•­ëª©

#### 1.1 GPU Passthrough ë¹„í™œì„±í™”
```nix
# lib/homelab-constants.nix
gpu = {
  enable = false;  # true â†’ false
  # ... ë‚˜ë¨¸ì§€ ì„¤ì • ìœ ì§€ (ë‚˜ì¤‘ ì°¸ê³ ìš©)
};
```

#### 1.2 VFIO ì»¤ë„ íŒŒë¼ë¯¸í„° ì œê±°
```nix
# modules/nixos/boot.nix
kernelParams = [
  "amd_iommu=on"
  "iommu=pt"
  # vfio-pci.ids=1002:1900 ì œê±°
];
```

#### 1.3 VM ì»¤ë„ íŒŒë¼ë¯¸í„° ì •ë¦¬
```nix
# vms/k8s-worker-1.nix
# amdgpu ê´€ë ¨ ì»¤ë„ íŒŒë¼ë¯¸í„° ëª¨ë‘ ì œê±°
boot.kernelParams = []; # GPU ê´€ë ¨ íŒŒë¼ë¯¸í„° ì œê±°
```

### í™•ì¸ ëª…ë ¹ì–´
```bash
# ë°°í¬ í›„ VM ìƒíƒœ í™•ì¸
just deploy
just vm-ping

# k8s-worker-1 ì •ìƒ ë¶€íŒ… í™•ì¸
ssh root@10.0.20.11 "systemctl is-system-running"
```

---

## Phase 2: í˜¸ìŠ¤íŠ¸ AMD GPU ì„¤ì •

### ëª©í‘œ
í˜¸ìŠ¤íŠ¸ì—ì„œ AMD iGPUë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë„ë¡ ROCm í™˜ê²½ êµ¬ì„±

### ì‘ì—… í•­ëª©

#### 2.1 AMD GPU ë“œë¼ì´ë²„ ì„¤ì •
```nix
# modules/nixos/amdgpu.nix (ì‹ ê·œ ìƒì„±)
{ pkgs, ... }: {
  # AMD GPU ë“œë¼ì´ë²„ initrd ë¡œë”©
  hardware.amdgpu.initrd.enable = true;

  # OpenCL ì§€ì›
  hardware.graphics = {
    enable = true;
    extraPackages = with pkgs; [
      rocmPackages.clr.icd
      rocmPackages.clr
    ];
  };

  # ROCm í™˜ê²½ ë³€ìˆ˜
  environment.variables = {
    ROC_ENABLE_PRE_VEGA = "1";  # gfx1103 ì§€ì›
  };
}
```

#### 2.2 ROCm íŒ¨í‚¤ì§€ ì„¤ì¹˜
```nix
# modules/nixos/amdgpu.nix (ê³„ì†)
environment.systemPackages = with pkgs; [
  rocmPackages.rocm-smi      # GPU ëª¨ë‹ˆí„°ë§
  rocmPackages.rocminfo      # GPU ì •ë³´
  rocmPackages.clinfo        # OpenCL ì •ë³´

  # AI/ML ì›Œí¬ë¡œë“œìš©
  rocmPackages.hip           # HIP ëŸ°íƒ€ì„
  rocmPackages.rocblas       # BLAS ë¼ì´ë¸ŒëŸ¬ë¦¬
];
```

#### 2.3 ì‚¬ìš©ì ê·¸ë£¹ ì„¤ì •
```nix
# modules/nixos/users.nix ë˜ëŠ” amdgpu.nix
users.users.limjihoon.extraGroups = [ "video" "render" ];
```

### í™•ì¸ ëª…ë ¹ì–´
```bash
# GPU ì¸ì‹ í™•ì¸
rocm-smi

# OpenCL ë””ë°”ì´ìŠ¤ í™•ì¸
clinfo | grep -i "device name"

# GPU ë©”ëª¨ë¦¬ í™•ì¸
cat /sys/class/drm/card0/device/mem_info_vram_total
```

---

## Phase 3: í˜¸ìŠ¤íŠ¸ K8s Worker ì„¤ì •

### ëª©í‘œ
í˜¸ìŠ¤íŠ¸ë¥¼ K8s worker nodeë¡œ êµ¬ì„±í•˜ì—¬ ê¸°ì¡´ VM í´ëŸ¬ìŠ¤í„°ì— join

### ì•„í‚¤í…ì²˜
```mermaid
flowchart LR
    subgraph Control["Control Plane (VM)"]
        MASTER["k8s-master<br/>10.0.20.10"]
    end

    subgraph Workers["Worker Nodes"]
        HOST["homelab (Host)<br/>10.0.10.5 / 10.0.20.5<br/>ğŸ® GPU"]
        VM1["k8s-worker-1 (VM)<br/>10.0.20.11"]
        VM2["k8s-worker-2 (VM)<br/>10.0.20.12"]
    end

    MASTER <--> HOST
    MASTER <--> VM1
    MASTER <--> VM2

    style HOST fill:#76b900,color:#fff
```

### ì‘ì—… í•­ëª©

#### 3.1 í˜¸ìŠ¤íŠ¸ K8s Worker ëª¨ë“ˆ ìƒì„±
```nix
# modules/nixos/k8s-worker-host.nix (ì‹ ê·œ ìƒì„±)
{ pkgs, homelabConstants, ... }: let
  masterInfo = homelabConstants.vms.k8s-master;
in {
  # K8s ì»¤ë„ ëª¨ë“ˆ
  boot.kernelModules = [ "overlay" "br_netfilter" ];
  boot.kernel.sysctl = {
    "net.bridge.bridge-nf-call-iptables" = 1;
    "net.ipv4.ip_forward" = 1;
  };

  # ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„
  virtualisation.containerd.enable = true;

  # Kubelet ì„¤ì •
  services.kubernetes = {
    roles = [ "node" ];
    masterAddress = masterInfo.ip;
    apiserverAddress = "https://${masterInfo.ip}:${toString masterInfo.ports.api}";
    easyCerts = true;

    kubelet = {
      kubeconfig.server = "https://${masterInfo.ip}:${toString masterInfo.ports.api}";
      extraOpts = "--node-labels=gpu=amd,node-type=baremetal";
    };
  };

  # K8s ë„êµ¬
  environment.systemPackages = with pkgs; [
    kubectl
    kubernetes
  ];

  # ë°©í™”ë²½
  networking.firewall.allowedTCPPorts = [
    10250  # kubelet
  ];
  networking.firewall.allowedTCPPortRanges = [
    { from = 30000; to = 32767; }  # NodePort
  ];
}
```

#### 3.2 configuration.nixì— ëª¨ë“ˆ ì¶”ê°€
```nix
# configuration.nix
imports = [
  # ... ê¸°ì¡´ imports
  ./modules/nixos/amdgpu.nix
  ./modules/nixos/k8s-worker-host.nix
];
```

#### 3.3 homelab-constants.nixì— í˜¸ìŠ¤íŠ¸ ë…¸ë“œ ì •ë³´ ì¶”ê°€
```nix
# lib/homelab-constants.nix
hosts = {
  homelab = {
    # ... ê¸°ì¡´ ì„¤ì •
    k8s = {
      role = "worker";
      labels = {
        "gpu" = "amd";
        "node-type" = "baremetal";
      };
    };
  };
};
```

### í™•ì¸ ëª…ë ¹ì–´
```bash
# í˜¸ìŠ¤íŠ¸ì—ì„œ kubelet ìƒíƒœ í™•ì¸
sudo systemctl status kubelet

# í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ëª©ë¡ (masterì—ì„œ)
kubectl get nodes -o wide

# ë…¸ë“œ ë ˆì´ë¸” í™•ì¸
kubectl get nodes --show-labels
```

---

## Phase 4: GPU ì›Œí¬ë¡œë“œ ë°°í¬

### ëª©í‘œ
í˜¸ìŠ¤íŠ¸ GPUë¥¼ í™œìš©í•˜ëŠ” AI/ML ì›Œí¬ë¡œë“œ (Ollama) ë°°í¬

### ì‘ì—… í•­ëª©

#### 4.1 AMD GPU Device Plugin (ì„ íƒì‚¬í•­)
```yaml
# k8s/amd-gpu-device-plugin.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: amd-gpu-device-plugin
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: amd-gpu-device-plugin
  template:
    spec:
      nodeSelector:
        gpu: amd
      containers:
      - name: amd-gpu-device-plugin
        image: rocm/k8s-device-plugin
        securityContext:
          privileged: true
        volumeMounts:
        - name: dev
          mountPath: /dev
      volumes:
      - name: dev
        hostPath:
          path: /dev
```

#### 4.2 Ollama ë°°í¬ (GPU ë…¸ë“œ íƒ€ê²ŸíŒ…)
```yaml
# k8s/ollama.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      nodeSelector:
        gpu: amd
        node-type: baremetal
      containers:
      - name: ollama
        image: ollama/ollama:rocm
        ports:
        - containerPort: 11434
        resources:
          limits:
            amd.com/gpu: 1
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
        securityContext:
          privileged: true
      volumes:
      - name: ollama-data
        hostPath:
          path: /var/lib/ollama
---
apiVersion: v1
kind: Service
metadata:
  name: ollama
spec:
  type: NodePort
  ports:
  - port: 11434
    nodePort: 31434
  selector:
    app: ollama
```

### í™•ì¸ ëª…ë ¹ì–´
```bash
# Ollama Pod ìƒíƒœ í™•ì¸
kubectl get pods -l app=ollama -o wide

# GPU ì‚¬ìš© í™•ì¸ (í˜¸ìŠ¤íŠ¸ì—ì„œ)
rocm-smi

# Ollama í…ŒìŠ¤íŠ¸
curl http://10.0.20.5:31434/api/tags
ollama run llama2
```

---

## Phase 5: ë„¤íŠ¸ì›Œí¬ ë° ë³´ì•ˆ ìµœì í™”

### ëª©í‘œ
Hybrid í´ëŸ¬ìŠ¤í„°ì˜ ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€ ìµœì í™” ë° ë³´ì•ˆ ê°•í™”

### ì‘ì—… í•­ëª©

#### 5.1 í˜¸ìŠ¤íŠ¸-VM ë„¤íŠ¸ì›Œí¬ ìµœì í™”
```mermaid
flowchart TB
    subgraph Host["í˜¸ìŠ¤íŠ¸ ë„¤íŠ¸ì›Œí¬"]
        BR["br0 (Bridge)"]
        VLAN10["VLAN 10<br/>Management"]
        VLAN20["VLAN 20<br/>Services"]
    end

    subgraph K8s["K8s ë„¤íŠ¸ì›Œí¬"]
        POD["Pod Network<br/>10.244.0.0/16"]
        SVC["Service Network<br/>10.96.0.0/12"]
    end

    BR --> VLAN10
    BR --> VLAN20
    VLAN20 --> POD
    POD --> SVC
```

#### 5.2 ë°©í™”ë²½ ê·œì¹™ ì •ë¦¬
```nix
# í˜¸ìŠ¤íŠ¸ ë°©í™”ë²½ (modules/nixos/k8s-worker-host.nix)
networking.firewall = {
  allowedTCPPorts = [
    6443   # API Server ì ‘ê·¼ (ì„ íƒ)
    10250  # Kubelet
    10255  # Kubelet read-only
    11434  # Ollama (ì§ì ‘ ì ‘ê·¼ ì‹œ)
  ];
  allowedTCPPortRanges = [
    { from = 30000; to = 32767; }  # NodePort
  ];
  # Flannel VXLAN
  allowedUDPPorts = [ 8472 8285 ];
};
```

#### 5.3 ì¸ì¦ì„œ ë° í† í° ê´€ë¦¬
```nix
# sopsì— k8s join í† í° ì¶”ê°€
# secrets/secrets.yaml
k8s:
  join-token: ENC[AES256_GCM,...]
```

---

## ìµœì¢… ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph Internet["External"]
        USER["ì‚¬ìš©ì"]
    end

    subgraph Homelab["Homelab Server (Bare Metal)"]
        subgraph Host["í˜¸ìŠ¤íŠ¸ OS (NixOS)"]
            GPU["AMD 780M<br/>ROCm"]
            KUBELET_H["Kubelet<br/>(GPU Worker)"]
            MICROVM["MicroVM Host"]
        end

        subgraph VMs["MicroVMs"]
            MASTER["k8s-master<br/>Control Plane<br/>10.0.20.10"]
            W1["k8s-worker-1<br/>CPU Worker<br/>10.0.20.11"]
            W2["k8s-worker-2<br/>CPU Worker<br/>10.0.20.12"]
        end

        subgraph Workloads["ì›Œí¬ë¡œë“œ"]
            OLLAMA["Ollama<br/>(GPU)"]
            APP["ì¼ë°˜ ì•±<br/>(CPU)"]
        end
    end

    USER --> MASTER
    MASTER --> KUBELET_H
    MASTER --> W1
    MASTER --> W2
    GPU --> KUBELET_H
    KUBELET_H --> OLLAMA
    W1 --> APP
    W2 --> APP
    MICROVM --> VMs

    style GPU fill:#76b900,color:#fff
    style KUBELET_H fill:#326ce5,color:#fff
    style MASTER fill:#326ce5,color:#fff
    style OLLAMA fill:#ff6f00,color:#fff
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: GPU ë¹„í™œì„±í™”
- [ ] `homelab-constants.nix`ì—ì„œ `gpu.enable = false`
- [ ] `boot.nix`ì—ì„œ VFIO íŒŒë¼ë¯¸í„° ì œê±°
- [ ] `vms/k8s-worker-1.nix`ì—ì„œ GPU ì»¤ë„ íŒŒë¼ë¯¸í„° ì œê±°
- [ ] ë°°í¬ ë° VM ì •ìƒ ì‘ë™ í™•ì¸

### Phase 2: í˜¸ìŠ¤íŠ¸ GPU ì„¤ì •
- [ ] `modules/nixos/amdgpu.nix` ìƒì„±
- [ ] ROCm íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [ ] ì‚¬ìš©ì ê·¸ë£¹ ì„¤ì •
- [ ] `rocm-smi` ë° `clinfo` í…ŒìŠ¤íŠ¸

### Phase 3: í˜¸ìŠ¤íŠ¸ K8s Worker
- [ ] `modules/nixos/k8s-worker-host.nix` ìƒì„±
- [ ] `configuration.nix`ì— ëª¨ë“ˆ ì¶”ê°€
- [ ] í˜¸ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„° join
- [ ] `kubectl get nodes`ì—ì„œ í˜¸ìŠ¤íŠ¸ ë…¸ë“œ í™•ì¸

### Phase 4: GPU ì›Œí¬ë¡œë“œ
- [ ] AMD GPU Device Plugin ë°°í¬ (ì„ íƒ)
- [ ] Ollama Deployment ë°°í¬
- [ ] GPU ì‚¬ìš© í™•ì¸
- [ ] LLM ì¶”ë¡  í…ŒìŠ¤íŠ¸

### Phase 5: ìµœì í™”
- [ ] ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€ ê²€í† 
- [ ] ë°©í™”ë²½ ê·œì¹™ ì •ë¦¬
- [ ] ì¸ì¦ì„œ/í† í° ê´€ë¦¬

---

## ì°¸ê³  ìë£Œ

- [NixOS AMD GPU](https://nixos.wiki/wiki/AMD_GPU)
- [ROCm on NixOS](https://github.com/NixOS/nixpkgs/tree/master/pkgs/development/rocm)
- [Kubernetes on NixOS](https://nixos.wiki/wiki/Kubernetes)
- [Ollama ROCm](https://ollama.ai/blog/amd-preview)

---

## ë³€ê²½ ì´ë ¥

| ë‚ ì§œ | ë‚´ìš© |
|------|------|
| 2026-01-27 | ì´ˆì•ˆ ì‘ì„± - GPU passthrough ì‹¤íŒ¨ë¡œ ì¸í•œ Hybrid êµ¬ì„± ê³„íš |
